{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import yaml\n",
    "import os.path as osp\n",
    "\n",
    "import igl\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch3d.ops import cot_laplacian\n",
    "\n",
    "from preprocess import mesh_sampling_method\n",
    "from dataset import MeshData\n",
    "from models import VAE_coma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7ad5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuliwuli/Desktop/predictor-net-measure/preprocess/mesh_sampling.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552411/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  torch.LongTensor([spmat.tocoo().row,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing the training and testing dataset...\n",
      "Normalization Done!\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config/general_config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# set the device, we can just assume we are using single GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = config[\"dataset\"]\n",
    "template = config[\"template\"]\n",
    "data_dir = osp.join('data', dataset)\n",
    "template_fp = osp.join('template', template)\n",
    "\n",
    "# get the up/down sampling matrix\n",
    "ds_factor = config[\"ds_factor\"]\n",
    "edge_index_list, down_transform_list, up_transform_list = mesh_sampling_method(data_fp=data_dir,\n",
    "                                                                                template_fp=template_fp,\n",
    "                                                                                ds_factors=ds_factor,\n",
    "                                                                                device=device)\n",
    "\n",
    "# create the model\n",
    "in_channels = config[\"model\"][\"in_channels\"]\n",
    "out_channels = config[\"model\"][\"out_channels\"]\n",
    "latent_channels = config[\"model\"][\"latent_channels\"]\n",
    "K = config[\"model\"][\"K\"]\n",
    "\n",
    "model = VAE_coma(in_channels = in_channels,\n",
    "                out_channels = out_channels,\n",
    "                latent_channels = latent_channels,\n",
    "                edge_index = edge_index_list,\n",
    "                down_transform = down_transform_list,\n",
    "                up_transform = up_transform_list,\n",
    "                K=K).to(device)\n",
    "\n",
    "# get the mean and std of the CAESAR dataset(Traing set)\n",
    "CAESAR_meshdata = MeshData(root=data_dir, template_fp=template_fp)\n",
    "# of shape (10002, 3). is torch.Tensor\n",
    "mean = CAESAR_meshdata.mean\n",
    "std = CAESAR_meshdata.std\n",
    "\n",
    "# load the template mesh\n",
    "template_v, template_f = igl.read_triangle_mesh(template_fp)\n",
    "\n",
    "# convert it into float32\n",
    "# as in cot_laplacian, it only supports toch.float32. inv_areas = torch.zeros(V, dtype=torch.float32, device=verts.device)\n",
    "template_v = template_v.astype('float32')\n",
    "# convert it into a list of pytorch Tensor.\n",
    "template_v = torch.from_numpy(template_v).cuda()\n",
    "template_f = torch.from_numpy(template_f).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1957cf2b",
   "metadata": {},
   "source": [
    "# Load PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee63b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pickle.load(open(\"out/pca/pca.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c15a9",
   "metadata": {},
   "source": [
    "# The Laplacian function to compute the Laplacian for each mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ec27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(vertex: torch.Tensor, faces: torch.Tensor, type: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the laplacian of a mesh.\n",
    "    Args:\n",
    "        vertex: FloatTensor of shape (V, 3) giving vertex positions for V vertices.\n",
    "        faces: LongTensor of shape (F, 3) giving faces.\n",
    "        type: String giving the type of laplacian to compute. Must be either 'mean' or 'vertex'.\n",
    "              mean: compute the mean laplacian value for all vertices.\n",
    "              vertex: compute the laplacian value for each vertex.\n",
    "    Returns:\n",
    "        laplacian: FloatTensor of shape (V, 1) giving the laplacian matrix for the mesh.\n",
    "                   OR, retuen the mean laplacian value for all vertices.\n",
    "    \"\"\"\n",
    "    if type not in ['mean', 'vertex', 'vector']:\n",
    "        raise ValueError('type must be one of mean, vertex or vector')\n",
    "\n",
    "    # Compute the cotangent weights.\n",
    "    L, inv_areas = cot_laplacian(vertex, faces)\n",
    "\n",
    "    # NOTE: The diagonal entries of the cotangent weights matrix returned by the method are 0\n",
    "    #       and need to be computed with the negative sum of the weights in each row.\n",
    "    L_sum = torch.sparse.sum(L, dim=1).to_dense().view(-1, 1)\n",
    "\n",
    "    # As shown in my thesis, the laplacian is given by: L_loss = L * M^{-1} * V, \n",
    "    # However, since the diagonal is zero, we modify it like: L_loss = (L - L_sum) * M^{-1} * V, \n",
    "    # where L is the cotangent weights matrix, \n",
    "    #       M is the mass matrix, with diagonal entries being 1/3 areas of the vertices,\n",
    "    #       V is the vertex positions.\n",
    "    \n",
    "    # NOTE: I have no idea where the 0.25 comes from.\n",
    "    #       In my opinion, it should be the weight should be 1/2 (cot alpha_{ij} + cot beta_{ij}).\n",
    "    #       So, the coefficient should be 0.5. \n",
    "    mass_matrix_inv = 0.25 * inv_areas\n",
    "\n",
    "    loss = (L.mm(vertex) - L_sum * vertex) * mass_matrix_inv\n",
    "\n",
    "    laplacian_loss = torch.norm(loss, dim=1)\n",
    "\n",
    "    if type == 'mean':\n",
    "        return torch.mean(laplacian_loss)\n",
    "    elif type == 'vertex':\n",
    "        return laplacian_loss\n",
    "    elif type == 'vector':\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce19ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lap(sample_vals: np.ndarray, mean: torch.Tensor, std: torch.Tensor, faces: torch.Tensor, model):\n",
    "    \"\"\"_summary_\n",
    "        load the model from model_path\n",
    "        sample several points from the latent space\n",
    "        for each corresponding mesh, return the laplacian loss(type = 'vertex')\n",
    "\n",
    "    Args:\n",
    "        sample_vals (np.ndarray): of shape (n_samples, ). We would sample n_samples from the latent space. And use the same vals for all 8 dimensions.\n",
    "        mean (torch.Tensor): of shape (10002, 3). is torch.Tensor\n",
    "        std (torch.Tensor): of shape (10002, 3). is torch.Tensor\n",
    "        faces (torch.Tensor): of shape (10002, 3). The faces of the template mesh.\n",
    "        model (VAE_coma): the model\n",
    "    \"\"\"\n",
    "\n",
    "    pca = model\n",
    "\n",
    "    # Sample from the latent space\n",
    "    # create a tensor of shape (10002, n_samples, 6)\n",
    "    # 10002 is the number of vertices of the template mesh, 6 is the number of latent dimensions\n",
    "    lap_vals = np.zeros((10002, sample_vals.shape[0], 6))\n",
    "    # M_matrix is of shape (8, 7)\n",
    "    M_matrix = np.load(\"out/pca/M.npy\")\n",
    "    \n",
    "    # for each latent dimension\n",
    "    for i in tqdm(range(6)):\n",
    "        # 7 = 6 + 1. 6 is the number of latent dimensions, we add one more bias term after that.\n",
    "        latent_val = np.zeros((sample_vals.shape[0], 7))\n",
    "\n",
    "        latent_val[:, i] = sample_vals\n",
    "        \n",
    "        # now the new_w is of shape (n_samples, 8)\n",
    "        new_w = np.matmul(M_matrix, latent_val.T).T\n",
    "                \n",
    "        # pca.inverse_transform() will return the mesh in the original space\n",
    "        v = pca.inverse_transform(new_w).reshape(-1, 10002, 3)    \n",
    "        v = v.astype('float32')\n",
    "        v = (torch.from_numpy(v) + mean).cuda()\n",
    "\n",
    "        for j in range(sample_vals.shape[0]):\n",
    "            # get the laplacian loss for each mesh\n",
    "            laplacian_loss = laplacian(v[j], faces, type='vertex')\n",
    "            lap_vals[:, j, i] = laplacian_loss.cpu().numpy()\n",
    "\n",
    "    return lap_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153afaa",
   "metadata": {},
   "source": [
    "# The Laplacian Loss on template mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97812326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean loss is 12.199\n",
      "The max loss is 1121.988\n",
      "The median loss is 4.100\n",
      "The std loss is 28.450\n"
     ]
    }
   ],
   "source": [
    "temp_lap_loss_mean = laplacian(template_v, template_f, 'mean')\n",
    "print(f\"The mean loss is {temp_lap_loss_mean:.3f}\")\n",
    "\n",
    "temp_lap_loss_vertex = laplacian(template_v, template_f, 'vertex')\n",
    "print(\"The max loss is {:.3f}\".format(torch.max(temp_lap_loss_vertex).item()))\n",
    "print(\"The median loss is {:.3f}\".format(torch.median(temp_lap_loss_vertex).item()))\n",
    "print(\"The std loss is {:.3f}\".format(torch.std(temp_lap_loss_vertex).item()))\n",
    "\n",
    "# plt.hist(temp_lap_loss_vertex .cpu().numpy(), bins=100)\n",
    "\n",
    "# temp_v, temp_f = igl.read_triangle_mesh(template_fp)\n",
    "# temp_mesh = trimesh.Trimesh(vertices=temp_v, faces=temp_f)\n",
    "# vertex_normals = trimesh.smoothing.get_vertices_normals(temp_mesh)\n",
    "# temp_lap_loss_vector = laplacian(template_v, template_f, 'vector').cpu().numpy()\n",
    "\n",
    "# lap = np.sum(temp_lap_loss_vector * vertex_normals, axis=1)\n",
    "# temp_mesh = pv.wrap(temp_mesh)\n",
    "# temp_mesh[\"lap_loss\"] = lap\n",
    "# temp_mesh.save(osp.join('result', 'laplacian', 'template.vtk'))\n",
    "\n",
    "# plt.hist(lap, bins=100)\n",
    "\n",
    "# print(\"The max loss is {:.3f}\".format(np.max(lap)))\n",
    "# print(\"The min loss is {:.3f}\".format(np.min(lap)))\n",
    "# print(\"The median loss is {:.3f}\".format(np.median(lap)))\n",
    "# print(\"The std loss is {:.3f}\".format(np.std(lap)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31daa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_v, temp_f = igl.read_triangle_mesh(template_fp)\n",
    "temp_mesh = trimesh.Trimesh(vertices=temp_v, faces=temp_f)\n",
    "temp_lap_loss_vertex = laplacian(template_v, template_f, 'vertex').cpu().numpy()\n",
    "\n",
    "temp_mesh = pv.wrap(temp_mesh)\n",
    "temp_mesh[\"lap_loss\"] = temp_lap_loss_vertex\n",
    "temp_mesh_diff = np.abs(temp_lap_loss_vertex - temp_lap_loss_vertex)\n",
    "temp_mesh[\"temp_diff\"] = temp_mesh_diff\n",
    "temp_mesh.save(osp.join('result', 'laplacian', 'template_mean.vtk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b6a69",
   "metadata": {},
   "source": [
    "# PCA on Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7ba254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 12.97it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_vals = np.linspace(-1, 1, 50)\n",
    "lap_loss = get_lap(sample_vals, mean, std, template_f, pca)\n",
    "\n",
    "# write the printed info into a file\n",
    "with open(\"result/pca/laplacian.txt\", \"w\") as f:\n",
    "    print(\"The mean loss for our method is {:.3f}\".format(np.mean(lap_loss)), file=f)\n",
    "    print(\"The max loss for our method is {:.3f}\".format(np.max(lap_loss)), file=f)\n",
    "    print(\"The median loss for our method is {:.3f}\".format(np.median(lap_loss)), file=f)\n",
    "    print(\"The std loss for our method is {:.3f}\".format(np.std(lap_loss)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d130bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10002, 3)\n",
      "(10002,)\n",
      "(10002,)\n"
     ]
    }
   ],
   "source": [
    "latent_vector = np.zeros((1, 7))\n",
    "for i in range(6):\n",
    "    latent_vector[:, i] = 0.1\n",
    "    \n",
    "M_matrix = np.load(\"out/pca/M.npy\")\n",
    "new_w = np.matmul(M_matrix, latent_vector.T).T\n",
    "v = pca.inverse_transform(new_w).reshape(10002, 3)\n",
    "v = v.astype('float32')\n",
    "v = torch.from_numpy(v)\n",
    "v = (v + mean).numpy()\n",
    "\n",
    "temp_v, temp_f = igl.read_triangle_mesh(template_fp)\n",
    "pca_mesh = trimesh.Trimesh(vertices=v, faces=temp_f)\n",
    "\n",
    "print(pca_mesh.vertices.shape)\n",
    "\n",
    "v = torch.from_numpy(v.astype('float32')).cuda()\n",
    "\n",
    "pca_lap_loss_vertex = laplacian(v, template_f, 'vertex').cpu().numpy()\n",
    "\n",
    "print(pca_lap_loss_vertex.shape)\n",
    "print(temp_lap_loss_vertex.shape)\n",
    "\n",
    "pca_lap_loss_diff = np.abs(pca_lap_loss_vertex - temp_lap_loss_vertex)\n",
    "pca_mean_mesh = pv.wrap(pca_mesh)\n",
    "pca_mean_mesh[\"lap_loss\"] = pca_lap_loss_vertex\n",
    "pca_mean_mesh[\"lap_loss_diff\"] = pca_lap_loss_diff\n",
    "pca_mean_mesh.save(osp.join('result', 'pca', 'pca_mean.vtk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669a98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"out/vae_coma/trainer12/20231220-123538/model.pth\"))\n",
    "# latent_vector = torch.zeros((1, 8)).cuda()\n",
    "# v = decode_func(latent_vector, model)\n",
    "# # convert to numpy array\n",
    "# v = v.detach().cpu()\n",
    "# # denormalize the vertices\n",
    "# v = v * std + mean\n",
    "# v = v.reshape(-1, 3)\n",
    "\n",
    "# temp_v, temp_f = igl.read_triangle_mesh(template_fp)\n",
    "# our_method_mesh = trimesh.Trimesh(vertices=v, faces=temp_f)\n",
    "# v = v.cuda()\n",
    "# our_method_lap_loss_vertex = laplacian(v, template_f, 'vertex').cpu().numpy()\n",
    "# our_method_lap_loss_diff = np.abs(our_method_lap_loss_vertex - temp_lap_loss_vertex)\n",
    "# our_method_mean_mesh = pv.wrap(our_method_mesh)\n",
    "# our_method_mean_mesh[\"lap_loss\"] = our_method_lap_loss_vertex\n",
    "# our_method_mean_mesh[\"lap_loss_diff\"] = our_method_lap_loss_diff\n",
    "# our_method_mean_mesh.save(osp.join('result', 'laplacian', 'our_method_mean.vtk'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "body_coma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
