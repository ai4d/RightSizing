{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import igl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from preprocess import mesh_sampling_method\n",
    "from dataset import MeshData\n",
    "from models import VAE_coma, GraphPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuhao/Desktop/height_weight_predictor/preprocess/mesh_sampling.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  torch.LongTensor([spmat.tocoo().row,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# read into the config file\n",
    "config_path = 'config/general_config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# set the device, we can just assume we are using single GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = config[\"dataset\"]\n",
    "template = config[\"template\"]\n",
    "data_dir = osp.join('data', dataset)\n",
    "template_fp = osp.join('template', template)\n",
    "\n",
    "# get the up/down sampling matrix\n",
    "ds_factor = config[\"ds_factor\"]\n",
    "edge_index_list, down_transform_list, up_transform_list = mesh_sampling_method(data_fp=data_dir,\n",
    "                                                                                template_fp=template_fp,\n",
    "                                                                                ds_factors=ds_factor,\n",
    "                                                                                device=device)\n",
    "\n",
    "# create the model\n",
    "in_channels = config[\"model\"][\"in_channels\"]\n",
    "out_channels = config[\"model\"][\"out_channels\"]\n",
    "latent_channels = config[\"model\"][\"latent_channels\"]\n",
    "K = config[\"model\"][\"K\"]\n",
    "\n",
    "# get the mean and std of the CAESAR dataset(Traing set)\n",
    "CAESAR_meshdata = MeshData(root=data_dir, template_fp=template_fp)\n",
    "# of shape (10002, 3). is torch.Tensor\n",
    "caesar_mean = CAESAR_meshdata.mean\n",
    "caesar_std = CAESAR_meshdata.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the predictor and the CoMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_predictor = GraphPredictor(in_channels = in_channels,\n",
    "                        out_channels = out_channels,\n",
    "                        edge_index = edge_index_list,\n",
    "                        down_transform = down_transform_list,\n",
    "                        K=K,\n",
    "                        type=\"weight\").to(device)\n",
    "weight_predictor.load_state_dict(torch.load(\"predictor_network/weight/predictor.pth\"))\n",
    "weight_mean = 76.13506\n",
    "weight_std = 19.45952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_predictor = GraphPredictor(in_channels = in_channels,\n",
    "                        out_channels = out_channels,\n",
    "                        edge_index = edge_index_list,\n",
    "                        down_transform = down_transform_list,\n",
    "                        K=K,\n",
    "                        type=\"height\").to(device)\n",
    "height_predictor.load_state_dict(torch.load(\"predictor_network/height/predictor.pth\"))\n",
    "height_mean = 1716.4373\n",
    "height_std = 107.98842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE_coma(in_channels = in_channels,\n",
    "                out_channels = out_channels,\n",
    "                latent_channels = latent_channels,\n",
    "                edge_index = edge_index_list,\n",
    "                down_transform = down_transform_list,\n",
    "                up_transform = up_transform_list,\n",
    "                K=K).to(device)\n",
    "model.load_state_dict(torch.load(\"out/vae_coma/weight/20230921-005450/model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the decoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_func(x, model):\n",
    "    num_layers = len(model.de_layers)\n",
    "    num_deblocks = num_layers - 2\n",
    "    for i, layer in enumerate(model.de_layers):\n",
    "        if i == 0:\n",
    "            x = layer(x)\n",
    "            x = x.view(-1, model.num_vert, model.out_channels[-1])\n",
    "        elif i != num_layers - 1:\n",
    "            x = layer(x, model.edge_index[num_deblocks - i],\n",
    "                        model.up_transform[num_deblocks - i])\n",
    "        else:\n",
    "            # last layer\n",
    "            x = layer(x, model.edge_index[0])\n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the computation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_height_weight(model, sample_vals: np.ndarray,  \n",
    "                      height_mean: float, height_std: float, weight_mean: float, weight_std: float, \n",
    "                      height_predictor, weight_predictor):\n",
    "    \"\"\"_summary_\n",
    "        load the model from model_path\n",
    "        sample points from the latent space\n",
    "        return the latent values and the corresponding height values and weight values\n",
    "\n",
    "    Args:\n",
    "        model: the generative model\n",
    "        sample_vals (np.ndarray): of shape (n_samples, ). We would sample n_samples from the latent space. And use the same vals for all 8 dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample from the latent space\n",
    "    # create a tensor of shape (n_samples, 8)\n",
    "    height_vals = np.zeros((sample_vals.shape[0], 8))\n",
    "    weight_vals = np.zeros((sample_vals.shape[0], 8))\n",
    "\n",
    "    # for each latent dimension\n",
    "    for i in tqdm(range(8)):\n",
    "        latent_val = torch.zeros((sample_vals.shape[0], 8))\n",
    "\n",
    "        latent_val[:, i] = torch.Tensor(sample_vals)\n",
    "        latent_val = latent_val.to(device) \n",
    "        \n",
    "        # decode the latent values\n",
    "        # of shape (n_samples, 10002, 3)\n",
    "        v = decode_func(latent_val, model)\n",
    "        \n",
    "        # get the weight and height of the mesh\n",
    "        weight = weight_predictor(v)\n",
    "        height = height_predictor(v)\n",
    "        \n",
    "        # convert to numpy array\n",
    "        weight = weight.cpu().detach().numpy().reshape(-1) * weight_std + weight_mean\n",
    "        height = height.cpu().detach().numpy().reshape(-1) * height_std + height_mean\n",
    "\n",
    "        height_vals[:, i] = height / 1000\n",
    "        weight_vals[:, i] = weight\n",
    "\n",
    "    return height_vals, weight_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(filename: str, sample_vals: np.ndarray, height_vals: np.ndarray, type: str):\n",
    "    \"\"\"_summary_\n",
    "        declare a plot of 8 subplots, 2 rows and 4 column\n",
    "        each subplot is a dot plot of the corresponding latent dimension\n",
    "        the x-axis is the latent value, the y-axis is the height\n",
    "        the figure size is tight to the subplots\n",
    "    Args:\n",
    "        filename (str): the file name to save the plot.\n",
    "        sample_vals (np.ndarray): of shape (n_samples, ). We would sample n_samples from the latent space. And use the same vals for all 8 dimensions.\n",
    "        height_vals (np.ndarray): of shape (n_samples, 8). 8 is the number of latent dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type not in [\"weight\", \"height\"]:\n",
    "        raise ValueError(\"type should be either weight or height\")\n",
    "\n",
    "    # Ensure that the dimensions match up correctly\n",
    "    if len(sample_vals) != height_vals.shape[0] or height_vals.shape[1] != 8:\n",
    "        raise ValueError(\"Input dimensions are mismatched!\")\n",
    "\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(23, 10), tight_layout=True)\n",
    "\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        # Plot each latent dimension\n",
    "        ax.scatter(sample_vals, height_vals[:, i], marker='o')\n",
    "        \n",
    "        # set the x-axis limit to be between -1 and 1\n",
    "        # set the y-axis limit to be between 1.5 and 2\n",
    "        ax.set_xlim(-1, 1)\n",
    "        if type == \"weight\":\n",
    "            ax.set_ylim(60, 90)\n",
    "        if type == \"height\":\n",
    "            ax.set_ylim(1.6,1.8)\n",
    "        \n",
    "        ax.set_title(\"Latent dimension {}\".format(i))\n",
    "\n",
    "    # Save the figure to the given filename\n",
    "    plt.savefig(filename)\n",
    "    \n",
    "    # Close the figure\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_vals = np.linspace(-1, 1, 50)\n",
    "height_vals, weight_vals = get_height_weight(model, sample_vals, height_mean, height_std, weight_mean, weight_std, height_predictor, weight_predictor)\n",
    "plot_latent(\"result/weight/weight.pdf\", sample_vals, weight_vals, type=\"weight\")\n",
    "plot_latent(\"result/weight/height.pdf\", sample_vals, height_vals, type=\"height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate mesh samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into the template mesh\n",
    "v, f = igl.read_triangle_mesh(template_fp)\n",
    "\n",
    "# generate a banch of meshes samples from the latent space\n",
    "def generate_mesh_samples(model, latent_vals: np.ndarray, mean, std, latent_dim):\n",
    "    \"\"\"_summary_\n",
    "        generate meshes from the latent values\n",
    "        save the meshes to the result folder\n",
    "\n",
    "    Args:\n",
    "        model_path (str): the path to the model file\n",
    "        latent_vals (np.ndarray): of shape (n_samples,). The latent values for the first latent dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    # move the mean and std to the device\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "\n",
    "\n",
    "    # create a tensor of shape (n_samples, 8)\n",
    "    latent_vectors = np.zeros((latent_vals.shape[0], 8))\n",
    "    # set the latent dimension to be latent_vals\n",
    "    latent_vectors[:, latent_dim] = latent_vals\n",
    "    # convert to torch.Tensor\n",
    "    latent_vectors = torch.Tensor(latent_vectors).cuda()\n",
    "\n",
    "    # decode the latent values\n",
    "    # of shape (n_samples, 10002, 3)\n",
    "    v = decode_func(latent_vectors, model)\n",
    "    # convert to numpy array\n",
    "    v = v.detach()\n",
    "    # denormalize the vertices\n",
    "    v = v * std + mean\n",
    "\n",
    "    v = v.cpu().numpy()\n",
    "\n",
    "    # save the meshes\n",
    "    for i in range(v.shape[0]):\n",
    "        vertex = v[i]\n",
    "        # find the lowest vertex\n",
    "        z_min = vertex[:, 2].min()\n",
    "        # move the lowest vertex to the origin\n",
    "        vertex[:, 2] = vertex[:, 2] - z_min\n",
    "\n",
    "        igl.write_triangle_mesh(\"result/weight/meshes/latent{}/{:.2f}.obj\".format(latent_dim, latent_vals[i]), vertex, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vals = np.array((-0.9, -0.6, -0.3, 0, 0.3, 0.6, 0.9))\n",
    "generate_mesh_samples(model=model, latent_vals=latent_vals, mean=caesar_mean, std=caesar_std, latent_dim=0)\n",
    "generate_mesh_samples(model=model, latent_vals=latent_vals, mean=caesar_mean, std=caesar_std, latent_dim=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "body_coma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
